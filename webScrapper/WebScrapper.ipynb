{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8BzyLmbjoQl_",
        "outputId": "680f5864-9081-401b-cad1-0eb03a1b1534",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag Counts:\n",
            "html: 1\n",
            "head: 1\n",
            "meta: 20\n",
            "title: 1\n",
            "script: 5\n",
            "link: 824\n",
            "body: 1\n",
            "a: 6383\n",
            "div: 625\n",
            "header: 2\n",
            "nav: 11\n",
            "input: 8\n",
            "label: 6\n",
            "span: 3984\n",
            "button: 17\n",
            "ul: 312\n",
            "li: 2199\n",
            "img: 221\n",
            "form: 1\n",
            "h2: 16\n",
            "main: 1\n",
            "h1: 1\n",
            "style: 25\n",
            "p: 174\n",
            "table: 53\n",
            "tbody: 53\n",
            "tr: 308\n",
            "td: 408\n",
            "b: 712\n",
            "i: 755\n",
            "th: 239\n",
            "sup: 859\n",
            "br: 124\n",
            "audio: 1\n",
            "source: 6\n",
            "track: 12\n",
            "abbr: 41\n",
            "h3: 35\n",
            "figure: 55\n",
            "figcaption: 55\n",
            "h4: 14\n",
            "video: 1\n",
            "blockquote: 3\n",
            "cite: 691\n",
            "small: 39\n",
            "map: 1\n",
            "area: 8\n",
            "h5: 3\n",
            "ol: 3\n",
            "bdi: 177\n",
            "q: 99\n",
            "code: 8\n",
            "dl: 1\n",
            "dd: 1\n",
            "noscript: 1\n",
            "footer: 1\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import re\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/Pakistan'\n",
        "#url = 'https://www.youtube.com/results?search_query=integrate+python+with+html'\n",
        "#url = 'https://www.w3schools.com/python/'\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "def filter_links(href):\n",
        "    return href and href.startswith('http')\n",
        "\n",
        "links = [link.get('href') for link in soup.find_all('a')]\n",
        "images = [image['src'] for image in soup.find_all('img')]\n",
        "paragraphs = [paragraph.text.strip() for paragraph in soup.find_all('p')]\n",
        "tables = []\n",
        "\n",
        "for table in soup.find_all('table'):\n",
        "    table_data = []\n",
        "    for row in table.find_all('tr'):\n",
        "        row_data = []\n",
        "        for cell in row.find_all(['td', 'th']):\n",
        "            row_data.append(cell.text.strip())\n",
        "\n",
        "        table_data.append(row_data)\n",
        "    tables.append(table_data)\n",
        "\n",
        "lists = []\n",
        "for ul in soup.find_all('ul'):\n",
        "    list_data = [li.text.strip() for li in ul.find_all('li')]\n",
        "    lists.append(list_data)\n",
        "\n",
        "forms = []\n",
        "for form in soup.find_all('form'):\n",
        "    form_data = {\n",
        "        \"action\": form.get('action'),\n",
        "        \"method\": form.get('method'),\n",
        "        \"inputs\": [{input_tag.get('name'): input_tag.get('value')} for input_tag in form.find_all('input')]\n",
        "    }\n",
        "    forms.append(form_data)\n",
        "\n",
        "options = []\n",
        "for select in soup.find_all('select'):\n",
        "    select_data = {\n",
        "        \"name\": select.get('name'),\n",
        "        \"options\": [option.text.strip() for option in select.find_all('option')]\n",
        "    }\n",
        "    options.append(select_data)\n",
        "\n",
        "buttons = [button.text.strip() for button in soup.find_all('button')]\n",
        "\n",
        "labels = [label.text.strip() for label in soup.find_all('label')]\n",
        "\n",
        "h_tags = {f\"h{i}\": [tag.text.strip() for tag in soup.find_all(f'h{i}')] for i in range(1, 6)}\n",
        "\n",
        "meta_tags = [str(tag) for tag in soup.find_all('meta')]\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"headings\": h_tags,\n",
        "    \"links\": links,\n",
        "    \"images\": images,\n",
        "    \"paragraphs\": paragraphs,\n",
        "    \"tables\": tables,\n",
        "    \"lists\": lists,\n",
        "    \"forms\": forms,\n",
        "    \"options\": options,\n",
        "    \"buttons\": buttons,\n",
        "    \"labels\": labels,\n",
        "    \"meta_tags\": meta_tags\n",
        "}\n",
        "\n",
        "with open('scraped_data.json', 'w', encoding='utf-8') as file:\n",
        "    json.dump(data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "tag_counts = {}\n",
        "for tag in soup.find_all():\n",
        "    tag_counts[tag.name] = tag_counts.get(tag.name, 0) + 1\n",
        "\n",
        "print(\"Tag Counts:\")\n",
        "for tag, count in tag_counts.items():\n",
        "    print(f\"{tag}: {count}\")\n"
      ]
    }
  ]
}